{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35576fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json, random\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 2025\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "# Normalization constants\n",
    "\n",
    "args = {\n",
    "    \"data\":      \"TestDataSet\",\n",
    "    \"labels\":    \"TestDataSet/labels_list.json\", \n",
    "    \"batch\":     128,\n",
    "    \"workers\":   8,\n",
    "    \"rand_start\": True\n",
    "}\n",
    "\n",
    "# ImageNet normalization\n",
    "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "std_tensor = torch.tensor(std, device=device, dtype=torch.float32).view(3,1,1)\n",
    "normalize = transforms.Normalize(mean.tolist(), std.tolist())\n",
    "\n",
    "min_val  = torch.tensor(((0 - mean) / std).reshape(3,1,1), device=device)\n",
    "max_val  = torch.tensor(((1 - mean) / std).reshape(3,1,1), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e74b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "dataset   = datasets.ImageFolder(root=args[\"data\"], transform=transform)\n",
    "loader    = DataLoader(dataset, batch_size=args[\"batch\"], shuffle=False, num_workers=args[\"workers\"])\n",
    "\n",
    "with open(args[\"labels\"]) as f:\n",
    "    idx2true = {i: int(e.split(\":\",1)[0]) for i, e in enumerate(json.load(f))}\n",
    "\n",
    "# ------------------- Load Pretrained Model -------------------\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
    "model.eval(),\n",
    "# ------------------- Evaluation Function -------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, idx2true, device, tag=\"\"):\n",
    "    top1 = top5 = tot = 0\n",
    "    for x, labs in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        labs = torch.tensor([idx2true[int(l)] for l in labs], device=device)\n",
    "        logits = model(x)\n",
    "        top1 += (logits.argmax(1) == labs).sum().item()\n",
    "        top5 += (logits.topk(5, 1)[1] == labs[:, None]).any(1).sum().item()\n",
    "        tot  += labs.size(0)\n",
    "    print(f\"{tag:<8}Top‑1 {top1/tot*100:6.2f}%   Top‑5 {top5/tot*100:6.2f}%\")\n",
    "    return top1 / tot, top5 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f50f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean   Top‑1  76.00%   Top‑5  94.20%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.76, 0.942)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------- Evaluate Clean Accuracy -------------------\n",
    "evaluate(model, loader, idx2true, device, \"Clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6e5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_batch(model, imgs, true_lbls, eps_norm, min_val, max_val):\n",
    "    imgs.requires_grad_(True)\n",
    "    logits = model(imgs)\n",
    "    F.cross_entropy(logits, true_lbls).backward()\n",
    "    adv = imgs + eps_norm * imgs.grad.data.sign()\n",
    "    adv = torch.max(torch.min(adv, max_val), min_val)\n",
    "    return adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5c253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, x, y, eps_n, alpha_n, steps, min_v, max_v, rand_start):\n",
    "    if rand_start:\n",
    "        x_adv = x + torch.empty_like(x).uniform_(-1, 1) * eps_n\n",
    "        x_adv = torch.clamp(x_adv, min_v, max_v)\n",
    "    else:\n",
    "        x_adv = x.clone()\n",
    "\n",
    "    for _ in range(steps):\n",
    "        x_adv = x_adv.detach().requires_grad_(True)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        F.cross_entropy(model(x_adv), y).backward()\n",
    "        grad_sign = x_adv.grad.sign()\n",
    "        x_adv = x_adv + alpha_n * grad_sign\n",
    "        x_adv = torch.clamp(x_adv, x - eps_n, x + eps_n)\n",
    "        x_adv = torch.clamp(x_adv, min_v, max_v)\n",
    "    return x_adv.detach()\n",
    "\n",
    "def targeted_pgd(model, x, target, eps_n, alpha_n, steps, min_v, max_v):\n",
    "    x_adv = x.clone()\n",
    "    for _ in range(steps):\n",
    "        x_adv = x_adv.detach().requires_grad_(True)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss = F.cross_entropy(model(x_adv), target)\n",
    "        loss.backward()\n",
    "        grad = x_adv.grad.sign()\n",
    "        x_adv = x_adv - alpha_n * grad\n",
    "        x_adv = torch.clamp(x_adv, x - eps_n, x + eps_n)\n",
    "        x_adv = torch.clamp(x_adv, min_v, max_v)\n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbe3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps   = 0.02\n",
    "steps = 5\n",
    "\n",
    "args = {\n",
    "    \"data\":      \"TestDataSet\",\n",
    "    \"labels\":    \"TestDataSet/labels_list.json\",\n",
    "    \"eps\":       eps,\n",
    "    \"steps\":     steps,\n",
    "    \"alpha\":     eps / steps,   \n",
    "    \"batch\":     128,\n",
    "    \"workers\":   8,\n",
    "    \"rand_start\": True,\n",
    "    \"out\":       \"adv_set_pgd.pt\"\n",
    "}\n",
    "\n",
    "eps_n   = torch.tensor(args[\"eps\"]   / std, device=device, dtype=torch.float32).view(3,1,1)\n",
    "alpha_n = torch.tensor(args[\"alpha\"] / std, device=device, dtype=torch.float32).view(3,1,1)\n",
    "# eps_n  = eps\n",
    "# alpha_n = args[\"alpha\"]\n",
    "# Craft adversarial examples\n",
    "adv_batches, lab_batches = [], []\n",
    "for imgs, labs in loader:\n",
    "    imgs = imgs.to(device, non_blocking=True)\n",
    "    true = torch.tensor([idx2true[int(l)] for l in labs], device=device)\n",
    "    adv = fgsm_batch(model, imgs, true, eps_n, min_val, max_val)\n",
    "\n",
    "    # Check ε constraint in raw pixels\n",
    "    raw_delta = (adv - imgs).abs() * torch.tensor(std, device=device).view(3,1,1)\n",
    "    assert raw_delta.max().item() <= eps + 1e-6\n",
    "\n",
    "    adv_batches.append(adv)\n",
    "    lab_batches.append(labs.to(device))\n",
    "\n",
    "adv_tensor = torch.cat(adv_batches)\n",
    "lab_tensor = torch.cat(lab_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73efcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM    Top‑1   3.60%   Top‑5  21.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.036, 0.21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on adversarial set\n",
    "adv_loader = DataLoader(TensorDataset(adv_tensor, lab_tensor), batch_size=args[\"batch\"])\n",
    "evaluate(model, adv_loader, idx2true, device, \"FGSM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51874d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD     Top‑1   0.00%   Top‑5   4.40%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.044)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------- PGD Attack Loop -------------------\n",
    "adv_batches, lab_batches = [], []\n",
    "for x, labs in loader:\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    y = torch.tensor([idx2true[int(l)] for l in labs], device=device)\n",
    "\n",
    "    adv = pgd_attack(model, x, y, eps_n, alpha_n,\n",
    "                     args[\"steps\"], min_val, max_val, args[\"rand_start\"])\n",
    "    \n",
    "    raw_delta = ((adv - x).abs() * std_tensor).max().item()\n",
    "    assert raw_delta <= args[\"eps\"] + 1e-6, f\"ε-constraint {raw_delta:.6f} > ε\"\n",
    "\n",
    "    adv_batches.append(adv)\n",
    "    lab_batches.append(labs.to(device))\n",
    "\n",
    "adv_tensor = torch.cat(adv_batches)\n",
    "lab_tensor = torch.cat(lab_batches)\n",
    "\n",
    "# ------------------- Evaluate PGD Accuracy -------------------\n",
    "pgd_loader = DataLoader(TensorDataset(adv_tensor, lab_tensor),\n",
    "                        batch_size=args[\"batch\"])\n",
    "evaluate(model, pgd_loader, idx2true, device, \"PGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560229d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TargetedTop‑1   0.60%   Top‑5   6.40%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.006, 0.064)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------- Parameters -------------------\n",
    "args = {\n",
    "    \"data\": \"TestDataSet\",\n",
    "    \"labels\": \"TestDataSet/labels_list.json\",\n",
    "    \"eps\": 0.02,\n",
    "    \"steps\": 5,           # 比 FGSM 更强\n",
    "    \"alpha\": 0.004,\n",
    "    \"batch\": 64,\n",
    "    \"workers\": 4,\n",
    "    \"target_class\": 0,     # 所有图像强制扰动成这个类 (tench)\n",
    "    \"out\": \"adv_set_targeted.pt\"\n",
    "}\n",
    "# ------------------- Targeted Attack Loop -------------------\n",
    "adv_batches, lab_batches = [], []\n",
    "for x, labs in loader:\n",
    "    x = x.to(device)\n",
    "    target = torch.full_like(labs, fill_value=args[\"target_class\"], device=device)\n",
    "\n",
    "    adv = targeted_pgd(model, x, target, eps_n, alpha_n,\n",
    "                       args[\"steps\"], min_val, max_val)\n",
    "\n",
    "    # Ensure constraint\n",
    "    raw_delta = ((adv - x).abs() * std_tensor).max().item()\n",
    "    assert raw_delta <= args[\"eps\"] + 1e-6, f\"ε-constraint {raw_delta:.6f} > ε\"\n",
    "\n",
    "    adv_batches.append(adv)\n",
    "    lab_batches.append(labs.to(device))\n",
    "\n",
    "adv_tensor = torch.cat(adv_batches)\n",
    "lab_tensor = torch.cat(lab_batches)\n",
    "\n",
    "# ------------------- Evaluate Targeted PGD Accuracy -------------------\n",
    "adv_loader = DataLoader(TensorDataset(adv_tensor, lab_tensor), batch_size=args[\"batch\"])\n",
    "evaluate(model, adv_loader, idx2true, device, \"Targeted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae2ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "898ca88b",
   "metadata": {},
   "source": [
    "### 🔁 PGD Evaluation Loop with Varying Steps\n",
    "\n",
    "We will evaluate the effect of PGD and Targeted PGD attacks under varying step sizes (5, 10, 15). For each configuration:\n",
    "\n",
    "- Clean accuracy is computed.\n",
    "- FGSM attack is compared.\n",
    "- PGD and targeted PGD are performed for each `steps` setting.\n",
    "- Accuracy results are printed.\n",
    "- Five sample images are saved for comparison across attacks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384f6cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM    Top‑1  20.00%   Top‑5  20.00%\n",
      "PGD-5   Top‑1   0.00%   Top‑5   0.00%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "targeted_pgd() got an unexpected keyword argument 'rand_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Targeted PGD (choose arbitrary incorrect target label: (true+1)%1000)\u001b[39;00m\n\u001b[32m     57\u001b[39m target_labels = (sample_true + \u001b[32m1\u001b[39m) % \u001b[32m1000\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m adv_target = \u001b[43mtargeted_pgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mmin_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m save_image(adv_target, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33madv_examples/tpgd_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m results[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTPGD-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = evaluate(model,\n\u001b[32m     62\u001b[39m     DataLoader(TensorDataset(adv_target, sample_labels), batch_size=\u001b[32m5\u001b[39m), idx2true, device, tag=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTPGD-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: targeted_pgd() got an unexpected keyword argument 'rand_start'"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "# Create directory for saving results\n",
    "os.makedirs(\"adv_examples\", exist_ok=True)\n",
    "\n",
    "step_list = [5, 10, 15]\n",
    "fgsm_eps = 0.02\n",
    "results = {}\n",
    "\n",
    "# Randomly select 5 images\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "for i, (img, lab) in enumerate(loader):\n",
    "    for j in range(len(img)):\n",
    "        if len(sample_images) < 5:\n",
    "            sample_images.append(img[j])\n",
    "            sample_labels.append(lab[j])\n",
    "        else:\n",
    "            break\n",
    "    if len(sample_images) >= 5:\n",
    "        break\n",
    "\n",
    "sample_images = torch.stack(sample_images).to(device)\n",
    "sample_labels = torch.tensor(sample_labels).to(device)\n",
    "sample_true = torch.tensor([idx2true[int(l)] for l in sample_labels], device=device)\n",
    "\n",
    "# Save clean versions\n",
    "save_image(sample_images, \"adv_examples/clean.png\")\n",
    "\n",
    "# FGSM attack\n",
    "sample_images.requires_grad_()\n",
    "out = model(sample_images)\n",
    "loss = F.cross_entropy(out, sample_true)\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "grad = sample_images.grad.data\n",
    "adv_fgsm = torch.clamp(sample_images + fgsm_eps / std_tensor * grad.sign(), min_val, max_val).detach()\n",
    "save_image(adv_fgsm, \"adv_examples/fgsm.png\")\n",
    "results[\"FGSM\"] = evaluate(model, DataLoader(TensorDataset(adv_fgsm, sample_labels), batch_size=5),\n",
    "                           idx2true, device, tag=\"FGSM\")\n",
    "\n",
    "# Loop over PGD steps\n",
    "for steps in step_list:\n",
    "    alpha = fgsm_eps / steps\n",
    "    alpha_n = torch.tensor(alpha / std, device=device).view(3,1,1)\n",
    "    eps_n = torch.tensor(fgsm_eps / std, device=device).view(3,1,1)\n",
    "\n",
    "    # Untargeted PGD\n",
    "    adv_pgd = pgd_attack(model, sample_images, sample_true, eps_n, alpha_n, steps,\n",
    "                         min_val, max_val, rand_start=True)\n",
    "    save_image(adv_pgd, f\"adv_examples/pgd_{steps}.png\")\n",
    "    results[f\"PGD-{steps}\"] = evaluate(model,\n",
    "        DataLoader(TensorDataset(adv_pgd, sample_labels), batch_size=5), idx2true, device, tag=f\"PGD-{steps}\")\n",
    "\n",
    "    # Targeted PGD (choose arbitrary incorrect target label: (true+1)%1000)\n",
    "    target_labels = (sample_true + 1) % 1000\n",
    "    adv_target = targeted_pgd(model, sample_images, target_labels, eps_n, alpha_n, steps,\n",
    "                              min_val, max_val, rand_start=False)\n",
    "    save_image(adv_target, f\"adv_examples/tpgd_{steps}.png\")\n",
    "    results[f\"TPGD-{steps}\"] = evaluate(model,\n",
    "        DataLoader(TensorDataset(adv_target, sample_labels), batch_size=5), idx2true, device, tag=f\"TPGD-{steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50429623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "print(\"\\n===== Accuracy Summary =====\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k:<10}: Top-1 {v[0]*100:.2f}%, Top-5 {v[1]*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
