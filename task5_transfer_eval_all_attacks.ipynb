{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Transferring Attacks\n",
    "Evaluate the classification accuracy (Top-1 and Top-5) on a DenseNet121 model for Clean and all `.pt` adversarial datasets in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from pathlib import Path\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(model, loader, idx2true, device):\n",
    "    t1 = t5 = n = 0\n",
    "    for x, labs in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = torch.tensor([idx2true[int(l)] for l in labs], device=device)\n",
    "        out = model(x)\n",
    "        t1 += (out.argmax(1) == y).sum().item()\n",
    "        t5 += (out.topk(5, 1)[1] == y[:, None]).any(1).sum().item()\n",
    "        n += y.size(0)\n",
    "    return 100 * t1 / n, 100 * t5 / n\n",
    "\n",
    "def adv_loader(path, batch_size, workers):\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    return DataLoader(TensorDataset(ckpt[\"images\"], ckpt[\"labels\"]),\n",
    "                      batch_size=batch_size, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "data_path = \"./TestDataSet\"\n",
    "label_path = \"./TestDataSet/labels_list.json\"\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "model_name = \"densenet121\"\n",
    "\n",
    "# Device and transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean.tolist(), std.tolist())\n",
    "])\n",
    "\n",
    "# Load clean dataset and label map\n",
    "clean_ds = datasets.ImageFolder(data_path, transform=transform)\n",
    "clean_ld = DataLoader(clean_ds, batch_size=batch_size, num_workers=num_workers)\n",
    "with open(label_path) as f:\n",
    "    idx2true = {i: int(e.split(\":\", 1)[0]) for i, e in enumerate(json.load(f))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/sj4025/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 106MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "mdl_ctor = getattr(models, model_name)\n",
    "mdl = mdl_ctor(weights=\"IMAGENET1K_V1\").to(device)\n",
    "mdl.eval()\n",
    "\n",
    "# Load all .pt files in current directory\n",
    "loaders = {\n",
    "    \"Clean\": clean_ld\n",
    "}\n",
    "for ptfile in sorted(Path(\".\").glob(\"*.pt\")):\n",
    "    label = ptfile.stem\n",
    "    loaders[label] = adv_loader(str(ptfile), batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transfer accuracy on densenet121 (32-batch)\n",
      "Dataset                               Top‑1   Top‑5\n",
      "---------------------------------------------\n",
      "Clean                                74.60%  93.60%\n",
      "FGSM                                 45.40%  75.80%\n",
      "PGD-Step-10                          48.00%  82.20%\n",
      "PGD-Step-15                          49.60%  82.60%\n",
      "PGD-Step-5                           45.80%  79.20%\n",
      "PGD-Targeted-Fixed-Step-10           72.20%  91.80%\n",
      "PGD-Targeted-Fixed-Step-15           73.20%  92.60%\n",
      "PGD-Targeted-Fixed-Step-5            72.00%  90.40%\n",
      "PGD-Targeted-Step-10                 71.80%  91.80%\n",
      "PGD-Targeted-Step-15                 72.80%  93.00%\n",
      "PGD-Targeted-Step-5                  71.00%  89.60%\n",
      "adv_set_patch_soft_eps0.3_step110    73.00%  92.40%\n",
      "adv_set_patch_soft_eps0.3_step50     71.00%  91.60%\n",
      "adv_set_patch_soft_eps0.3_step80     71.60%  92.60%\n",
      "adv_set_patch_soft_eps0.3_step80_untargeted  68.80%  91.00%\n",
      "adv_set_patch_soft_eps0.5_step80     72.00%  91.40%\n",
      "adv_set_patch_soft_eps0.9_step80     71.80%  90.40%\n",
      "adv_set_patch_soft_random_0.3_80     71.60%  92.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all\n",
    "print(f\"\\nTransfer accuracy on {model_name} ({batch_size}-batch)\")\n",
    "print(\"Dataset                               Top‑1   Top‑5\")\n",
    "print(\"-\" * 45)\n",
    "for name, ld in loaders.items():\n",
    "    a1, a5 = accuracy(mdl, ld, idx2true, device)\n",
    "    print(f\"{name:<35} {a1:6.2f}% {a5:6.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
